resources:
  requests:
    cpu: 10m
    memory: 16Mi
operatorNamespace: &namespace storage
monitoring:
  enabled: false
  createPrometheusRules: false
ingress:
  dashboard:
    annotations:
      traefik.ingress.kubernetes.io/router.middlewares: network-forward-auth@kubernetescrd
    ingressClassName: traefik-external
    host:
      name: &host rook-ceph.cloud.icylair.com
      path: /
    tls:
    - hosts:
        - *host
      secretName: icylair-com-all-prod
# toolbox:
#   enabled: true
configOverride: |
  [global]
  bdev_enable_discard = true
  bdev_async_discard = true
  osd_class_update_on_start = false

cephClusterSpec:
  logCollector:
    enabled: false
  mgr:
    count: 1
    modules:
      - name: pg_autoscaler
        enabled: true
  mon:
    count: 1

  resources:
    mgr:
      requests:
        cpu: 5m
        memory: 16Mi
      limits:
        memory: 2Gi
        cpu: &cpu_limit_dbg 200m
    mon:
      requests:
        cpu: 5m
        memory: 16Mi
      limits:
        memory: 1Gi
        cpu: *cpu_limit_dbg
    osd:
      requests:
        cpu: 5m
        memory: 16Mi
      limits:
        memory: 6Gi
        cpu: *cpu_limit_dbg
    mgr-sidecar:
      requests:
        cpu: 5m
        memory: 16Mi
      limits:
        memory: 256Mi
        cpu: *cpu_limit_dbg
    prepareosd:
      requests:
        cpu: 5m
        memory: 16Mi
      limits:
        cpu: *cpu_limit_dbg
    crashcollector:
      requests:
        cpu: 5m
        memory: 16Mi
      limits:
        memory: "60Mi"
        cpu: *cpu_limit_dbg
    logcollector:
      requests:
        cpu: 5m
        memory: 16Mi
      limits:
        memory: "1Gi"
        cpu: *cpu_limit_dbg
    cleanup:
      requests:
        cpu: 5m
        memory: 16Mi
      limits:
        memory: "1Gi"
        cpu: *cpu_limit_dbg
    exporter:
      requests:
        cpu: 5m
        memory: 16Mi
      limits:
        memory: "128Mi"
        cpu: *cpu_limit_dbg
  dashboard:
    enabled: true
    urlPrefix: /
    ssl: false
    # prometheusEndpoint: http://prometheus-operated.observability.svc.cluster.local:9090
#   network:
#     provider: host
#     connections:
#       requireMsgr2: true
#   storage:
#     useAllNodes: true
#     useAllDevices: true
#     deviceFilter: nvme0n1
#     config:
#       osdsPerDevice: "1"
cleanupPolicy:
  confirmation: "yes-really-destroy-data"
placement:
  # all:
  #   nodeAffinity:
  #     requiredDuringSchedulingIgnoredDuringExecution:
  #       nodeSelectorTerms:
  #         - matchExpressions:
  #           - key: storage/ceph
  #             operator: In
  #             values:
  #             - "true"
#     mgr: &placement
#       nodeAffinity:
#         requiredDuringSchedulingIgnoredDuringExecution:
#           nodeSelectorTerms:
#             - matchExpressions:
#                 - key: node-role.kubernetes.io/control-plane
#                   operator: Exists
#     mon: *placement
  removeOSDsIfOutAndSafeToRemove: true
cephBlockPools:
  - name: ceph-blockpool
    spec:
      failureDomain: host
      replicated:
        size: 1
    storageClass:
      enabled: true
      name: ceph-block
      isDefault: false
      reclaimPolicy: Delete
      allowVolumeExpansion: true
      volumeBindingMode: Immediate
      parameters:
        imageFormat: "2"
        imageFeatures: layering
        csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
        csi.storage.k8s.io/provisioner-secret-namespace: *namespace
        csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
        csi.storage.k8s.io/controller-expand-secret-namespace: *namespace
        csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
        csi.storage.k8s.io/node-stage-secret-namespace: *namespace
        csi.storage.k8s.io/fstype: ext4
  # - name: ceph-localpathpool
cephBlockPoolsVolumeSnapshotClass:
  enabled: true
  name: csi-ceph-blockpool
  isDefault: true
  deletionPolicy: Delete
cephFileSystems:
  - name: &cephFileSystemName ceph-filesystem
    spec:
      metadataPool:
        replicated:
          size: 1
      dataPools:
        - failureDomain: host
          replicated:
            size: 2
          name: data0
      metadataServer:
        activeCount: 1
        activeStandby: true
        priorityClassName: system-cluster-critical
        placement:
          topologySpreadConstraints:
            - maxSkew: 1
              topologyKey: kubernetes.io/hostname
              whenUnsatisfiable: DoNotSchedule
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: ceph-mds
                  app.kubernetes.io/part-of: *cephFileSystemName
        resources:
          requests:
            cpu: 100m
            memory: 512Mi
          limits:
            memory: 4Gi
    storageClass:
      enabled: false
      isDefault: false
      name: ceph-filesystem
      pool: data0
      reclaimPolicy: Delete
      allowVolumeExpansion: true
      volumeBindingMode: Immediate
      parameters:
        csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner
        csi.storage.k8s.io/provisioner-secret-namespace: *namespace
        csi.storage.k8s.io/controller-expand-secret-name: rook-csi-cephfs-provisioner
        csi.storage.k8s.io/controller-expand-secret-namespace: *namespace
        csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node
        csi.storage.k8s.io/node-stage-secret-namespace: *namespace
        csi.storage.k8s.io/fstype: ext4
cephFileSystemVolumeSnapshotClass:
  enabled: true
  name: csi-ceph-filesystem
  isDefault: false
  deletionPolicy: Delete
cephObjectStores:
  - name: ceph-objectstore
    spec:
      metadataPool:
        failureDomain: host
        replicated:
          size: 1
      dataPool:
        failureDomain: host
        erasureCoded:
          dataChunks: 2
          codingChunks: 1
      preservePoolsOnDelete: true
      gateway:
        hostNetwork: false
        port: 80
        resources:
          requests:
            cpu: 100m
            memory: 512Mi
          limits:
            memory: 2Gi
        instances: 2
        priorityClassName: system-cluster-critical
      healthCheck:
        bucket:
          interval: 60s
    storageClass:
      enabled: true
      name: ceph-bucket
      reclaimPolicy: Delete
      volumeBindingMode: Immediate
      parameters:
        region: us-east-1
    # ingress:
    #   enabled: true
    #   annotations:
    #     external-dns.alpha.kubernetes.io/target: internal.devbu.io
    #     nginx.ingress.kubernetes.io/proxy-body-size: "0"
    #     nginx.ingress.kubernetes.io/proxy-request-buffering: "off"
    #   ingressClassName: internal
    #   host:
    #     name: rgw.devbu.io
    #     path: /