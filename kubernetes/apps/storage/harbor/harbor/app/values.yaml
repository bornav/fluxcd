updateStrategy:
  type: Recreate
diagnosticMode:
  enabled: false
  command:
    - sleep
  args:
    - infinity
# global:
#   imageRegistry: ""
#   ## E.g.
#   ## imagePullSecrets:
#   ##   - myRegistryKeySecretName
#   ##
#   imagePullSecrets: []
#   defaultStorageClass: ""
#   storageClass: ""
#   ## Compatibility adaptations for Kubernetes platforms
#   ##
#   compatibility:
#     ## Compatibility adaptations for Openshift
#     ##
#     openshift:
#       ## @param global.compatibility.openshift.adaptSecurityContext Adapt the securityContext sections of the deployment to make them compatible with Openshift restricted-v2 SCC: remove runAsUser, runAsGroup and fsGroup and let the platform use their allowed default IDs. Possible values: auto (apply if the detected running cluster is Openshift), force (perform the adaptation always), disabled (do not perform adaptation)
#       ##
#       adaptSecurityContext: auto

adminPassword: ""
externalURL: https://harbor.icylair.com

## @param exposureType The way to expose Harbor. Allowed values are [ ingress \| proxy ]
## Use "proxy" to use a deploy NGINX proxy in front of Harbor services
## Use "ingress" to use an Ingress Controller as proxy
##
exposureType: ingress

ingress:
  core:
    ingressClassName: "traefik-external"
    hostname: harbor.icylair.com
    ## annotations:
    ##   kubernetes.io/ingress.class: nginx
    ##   cert-manager.io/cluster-issuer: cluster-issuer-name
    ##
    # annotations:
    #   ingress.kubernetes.io/ssl-redirect: "true"
    #   ingress.kubernetes.io/proxy-body-size: "0"
    #   nginx.ingress.kubernetes.io/ssl-redirect: "true"
    #   nginx.ingress.kubernetes.io/proxy-body-size: "0"

    ## @param ingress.core.tls Enable TLS configuration for the host defined at `ingress.core.hostname` parameter
    ## TLS certificates will be retrieved from a TLS secret with name: `{{- printf "%s-tls" .Values.ingress.core.hostname }}`
    ## You can:
    ##   - Use the `ingress.core.secrets` parameter to create this TLS secret
    ##   - Rely on cert-manager to create it by setting the corresponding annotations
    ##   - Rely on Helm to create self-signed certificates by setting `ingress.core.selfSigned=true`
    ##
    tls: true
    ## @param ingress.core.selfSigned Create a TLS secret for this ingress record using self-signed certificates generated by Helm
    ##
    selfSigned: false
    ## @param ingress.core.extraHosts An array with additional hostname(s) to be covered with the ingress record
    ## e.g:
    ## extraHosts:
    ##   - name: core.harbor.domain
    ##     path: /
    ##
    extraHosts: []
    ## @param ingress.core.extraPaths An array with additional arbitrary paths that may need to be added to the ingress under the main host
    ## e.g:
    ## extraPaths:
    ## - path: /*
    ##   backend:
    ##     serviceName: ssl-redirect
    ##     servicePort: use-annotation
    ##
    extraPaths: []
    ## @param ingress.core.extraTls TLS configuration for additional hostname(s) to be covered with this ingress record
    ## ref: https://kubernetes.io/docs/concepts/services-networking/ingress/#tls
    ## e.g:
    ## extraTls:
    ## - hosts:
    ##     - core.harbor.domain
    ##   secretName: core.harbor.domain-tls
    ##
    extraTls: []
    ## @param ingress.core.secrets Custom TLS certificates as secrets
    ## NOTE: 'key' and 'certificate' are expected in PEM format
    ## NOTE: 'name' should line up with a 'secretName' set further up
    ## If it is not set and you're using cert-manager, this is unneeded, as it will create a secret for you with valid certificates
    ## If it is not set and you're NOT using cert-manager either, self-signed certificates will be created valid for 365 days
    ## It is also possible to create and manage the certificates outside of this helm chart
    ## Please see README.md for more information
    ## e.g:
    ## secrets:
    ##   - name: core.harbor.domain-tls
    ##     key: |-
    ##       -----BEGIN RSA PRIVATE KEY-----
    ##       ...
    ##       -----END RSA PRIVATE KEY-----
    ##     certificate: |-
    ##       -----BEGIN CERTIFICATE-----
    ##       ...
    ##       -----END CERTIFICATE-----
    ##
    secrets: []
    ## @param ingress.core.extraRules Additional rules to be covered with this ingress record
    ## ref: https://kubernetes.io/docs/concepts/services-networking/ingress/#ingress-rules
    ## e.g:
    ## extraRules:
    ## - host: example.local
    ##     http:
    ##       path: /
    ##       backend:
    ##         service:
    ##           name: example-svc
    ##           port:
    ##             name: http
    ##
    extraRules: []
    ##
## @section Persistence Parameters
##

## The persistence is enabled by default and a default StorageClass
## is needed in the k8s cluster to provision volumes dynamically.
## Specify another StorageClass in the "storageClass" or set "existingClaim"
## if you have already existing persistent volumes to use
##
## For storing images and charts, you can also use "azure", "gcs", "s3",
## "swift" or "oss". Set it in the "imageChartStorage" section
##
persistence:
  ## @param persistence.enabled Enable the data persistence or not
  ##
  enabled: true
  ## Resource Policy
  ## @param persistence.resourcePolicy Setting it to `keep` to avoid removing PVCs during a helm delete operation. Leaving it empty will delete PVCs after the chart deleted
  ##
  resourcePolicy: "keep"
  persistentVolumeClaim:
    registry:
      existingClaim: "harbor-data"
      subPath: "registry"
    jobservice:
      existingClaim: "harbor-data"
      subPath: "jobservice"
    trivy:
      existingClaim: "harbor-data"
      subPath: "trivy"
  ## Define which storage backend is used for registry to store
  ## images and charts.
  ## ref: https://github.com/docker/distribution/blob/master/docs/configuration.md#storage
  ##
  imageChartStorage:
    disableredirect: true
    type: s3
    ## Images/charts storage parameters when type is "s3"
    ## ref: https://docs.docker.com/registry/storage-drivers/s3/
    ## @param persistence.imageChartStorage.s3.region S3 storage type setting: Region
    ## @param persistence.imageChartStorage.s3.bucket S3 storage type setting: Bucket name
    ## @param persistence.imageChartStorage.s3.accesskey S3 storage type setting: Access key name
    ## @param persistence.imageChartStorage.s3.secretkey S3 storage type setting: Secret Key name
    ## @param persistence.imageChartStorage.s3.regionendpoint S3 storage type setting: Region Endpoint
    ## @param persistence.imageChartStorage.s3.encrypt S3 storage type setting: Encrypt
    ## @param persistence.imageChartStorage.s3.keyid S3 storage type setting: Key ID
    ## @param persistence.imageChartStorage.s3.secure S3 storage type setting: Secure
    ## @param persistence.imageChartStorage.s3.skipverify S3 storage type setting: TLS skip verification
    ## @param persistence.imageChartStorage.s3.v4auth S3 storage type setting: V4 authorization
    ## @param persistence.imageChartStorage.s3.chunksize S3 storage type setting: V4 authorization
    ## @param persistence.imageChartStorage.s3.rootdirectory S3 storage type setting: Root directory name
    ## @param persistence.imageChartStorage.s3.storageClass S3 storage type setting: Storage class
    ## @param persistence.imageChartStorage.s3.sse S3 storage type setting: SSE name
    ## @param persistence.imageChartStorage.s3.multipartcopythresholdsize S3 storage type setting: Threshold size for multipart copy
    ##
    s3:
      region: us-west-1
      bucket: harbor
      accesskey: ""
      secretkey: ""
      regionendpoint: http://wireguard.network.svc.cluster.local:9010
      encrypt: ""
      keyid: ""
      secure: ""
      skipverify: ""
      v4auth: ""
      chunksize: ""
      rootdirectory: ""
      storageClass: ""
      sse: ""
      multipartcopythresholdsize: ""
tracing:
  ## @param tracing.enabled Enable tracing
  ##
  enabled: false
  ## @param tracing.sampleRate Tracing sample rate from 0 to 1
  ##
  sampleRate: 1
  ## @param tracing.namespace Used to differentiate traces between different harbor services
  ##
  namespace: ""
  ## @param tracing.attributes A key value dict containing user defined attributes used to initialize the trace provider
  ## e.g:
  ## attributes:
  ##   application: harbor
  ##
  attributes: {}
  ## @extra tracing.jaeger Configuration for exporting to jaeger. If using jaeger collector mode, use endpoint, username and password. If using jaeger agent mode, use agentHostname and agentPort.
  ## e.g:
  ## jaeger:
  ##   enabled: true
  ##   endpoint: http://hostname:14268/api/traces
  ##   username: "jaeger-username"
  ##   password: "jaeger-password"
  ## @param tracing.jaeger.enabled Enable jaeger export
  ## @param tracing.jaeger.endpoint Jaeger endpoint
  ## @param tracing.jaeger.username Jaeger username
  ## @param tracing.jaeger.password Jaeger password
  ## @param tracing.jaeger.agentHost Jaeger agent hostname
  ## @param tracing.jaeger.agentPort Jaeger agent port
  ##
  jaeger:
    enabled: false
    endpoint: ""
    username: ""
    password: ""
    agentHost: ""
    agentPort: ""
  ## @extra tracing.otel Configuration for exporting to an otel endpoint
  ## @param tracing.otel.enabled Enable otel export
  ## @param tracing.otel.endpoint The hostname and port for an otel compatible backend
  ## @param tracing.otel.urlpath Url path of otel endpoint
  ## @param tracing.otel.compression Enable data compression
  ## @param tracing.otel.timeout The timeout for data transfer
  ## @param tracing.otel.insecure Ignore cert verification for otel backend
  ##
  otel:
    enabled: false
    endpoint: "hostname:4318"
    urlpath: "/v1/traces"
    compression: false
    timeout: 10s
    insecure: true
## @section Volume Permissions parameters
##

## Init containers parameters:
## certificateVolume: Copy /etc/ssl/certs to a volume so that they can be updated when a read-only volume is in use.
##
certificateVolume:
  ## Init container resource requests and limits
  ## ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## @param certificateVolume.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, micro, small, medium, large, xlarge, 2xlarge). This is ignored if certificateVolume.resources is set (certificateVolume.resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "nano"
  ## @param certificateVolume.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources: {}
## volumePermissions: Change the owner and group of the persistent volume(s) mountpoint(s) to 'runAsUser:fsGroup' on each node
##
volumePermissions:
  ## @param volumePermissions.enabled Enable init container that changes the owner and group of the persistent volume
  ##
  enabled: true
  ## @param volumePermissions.image.registry [default: REGISTRY_NAME] Init container volume-permissions image registry
  ## @param volumePermissions.image.repository [default: REPOSITORY_NAME/os-shell] Init container volume-permissions image repository
  ## @skip volumePermissions.image.tag Init container volume-permissions image tag (immutable tags are recommended)
  ## @param volumePermissions.image.digest Init container volume-permissions image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag
  ## @param volumePermissions.image.pullPolicy Init container volume-permissions image pull policy
  ## @param volumePermissions.image.pullSecrets Init container volume-permissions image pull secrets
  ##
  image:
    registry: docker.io
    repository: bitnami/os-shell
    tag: 12-debian-12-r27
    digest: ""
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ## Example:
    ## pullSecrets:
    ##   - myRegistryKeySecretName
    ##
    pullSecrets: []
  ## Init container resource requests and limits
  ## ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## @param volumePermissions.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, micro, small, medium, large, xlarge, 2xlarge). This is ignored if volumePermissions.resources is set (volumePermissions.resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "nano"
  ## @param volumePermissions.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources: {}
  ## Init container' Security Context
  ## Note: the chown of the data folder is done to containerSecurityContext.runAsUser
  ## and not the below volumePermissions.containerSecurityContext.runAsUser
  ## @param volumePermissions.containerSecurityContext.enabled Enable init container Security Context
  ## @param volumePermissions.containerSecurityContext.seLinuxOptions [object,nullable] Set SELinux options in container
  ## @param volumePermissions.containerSecurityContext.runAsUser User ID for the init container
  ##
  containerSecurityContext:
    enabled: true
    seLinuxOptions: {}
    runAsUser: 0

portal:
  tolerations: 
    - key: node-role.kubernetes.io/master
      value: "true"
      effect: NoSchedule
  nodeSelector:
    kubernetes.io/arch: amd64
## @section Harbor Core Parameters
##
core:
  tolerations: 
    - key: node-role.kubernetes.io/master
      value: "true"
      effect: NoSchedule
  nodeSelector:
    kubernetes.io/arch: amd64
jobservice:
  tolerations: 
    - key: node-role.kubernetes.io/master
      value: "true"
      effect: NoSchedule
  nodeSelector:
    kubernetes.io/arch: amd64
registry:
  tolerations: 
    - key: node-role.kubernetes.io/master
      value: "true"
      effect: NoSchedule
  nodeSelector:
    kubernetes.io/arch: amd64
  
trivy:
  enabled: false
exporter:
  ## Bitnami Harbor Exporter image
  ## ref: https://hub.docker.com/r/bitnami/harbor-exporter/tags/
  ## @param exporter.image.registry [default: REGISTRY_NAME] Harbor Exporter image registry
  ## @param exporter.image.repository [default: REPOSITORY_NAME/harbor-exporter] Harbor Exporter image repository
  ## @skip exporter.image.tag Harbor Exporter image tag
  ## @param exporter.image.digest Harbor Exporter image image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag
  ## @param exporter.image.pullPolicy Harbor exporter image pull policy
  ## @param exporter.image.pullSecrets Specify docker-registry secret names as an array
  ## @param exporter.image.debug Specify if debug logs should be enabled
  ##
  image:
    registry: docker.io
    repository: bitnami/harbor-exporter
    tag: 2.11.1-debian-12-r6
    digest: ""
    ## Specify a imagePullPolicy
    ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
    ## ref: https://kubernetes.io/docs/concepts/containers/images/#pre-pulled-images
    ##
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ## e.g:
    ## pullSecrets:
    ##   - myRegistryKeySecretName
    ##
    pullSecrets: []
    ## Enable debug mode
    ##
    debug: false
  ## @param exporter.command Override default container command (useful when using custom images)
  ##
  command: []
  ## @param exporter.args Override default container args (useful when using custom images)
  ##
  args: []
  ## @param exporter.extraEnvVars Array containing extra env vars
  ## For example:
  ##  - name: HARBOR_DATABASE_SSLMODE
  ##    value: verify-ca
  ##
  extraEnvVars: []
  ## @param exporter.extraEnvVarsCM ConfigMap containing extra env vars
  ##
  extraEnvVarsCM: ""
  ## @param exporter.extraEnvVarsSecret Secret containing extra env vars (in case of sensitive data)
  ##
  extraEnvVarsSecret: ""
  ## @param exporter.containerPorts.metrics Harbor Exporter HTTP container port
  ##
  containerPorts:
    metrics: 8001
  ## @param exporter.replicaCount The replica count
  ##
  replicaCount: 1
  ## Harbor Exporter containers' liveness probe
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes
  ## @param exporter.livenessProbe.enabled Enable livenessProbe
  ## @param exporter.livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe
  ## @param exporter.livenessProbe.periodSeconds Period seconds for livenessProbe
  ## @param exporter.livenessProbe.timeoutSeconds Timeout seconds for livenessProbe
  ## @param exporter.livenessProbe.failureThreshold Failure threshold for livenessProbe
  ## @param exporter.livenessProbe.successThreshold Success threshold for livenessProbe
  ##
  livenessProbe:
    enabled: true
    initialDelaySeconds: 20
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
    successThreshold: 1
  ## Harbor Exporter containers' readiness probe
  ## ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes
  ## @param exporter.readinessProbe.enabled Enable readinessProbe
  ## @param exporter.readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe
  ## @param exporter.readinessProbe.periodSeconds Period seconds for readinessProbe
  ## @param exporter.readinessProbe.timeoutSeconds Timeout seconds for readinessProbe
  ## @param exporter.readinessProbe.failureThreshold Failure threshold for readinessProbe
  ## @param exporter.readinessProbe.successThreshold Success threshold for readinessProbe
  ##
  readinessProbe:
    enabled: true
    initialDelaySeconds: 20
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 6
    successThreshold: 1
  ## @param exporter.startupProbe.enabled Enable startupProbe on Harbor Exporter containers
  ## @param exporter.startupProbe.initialDelaySeconds Initial delay seconds for startupProbe
  ## @param exporter.startupProbe.periodSeconds Period seconds for startupProbe
  ## @param exporter.startupProbe.timeoutSeconds Timeout seconds for startupProbe
  ## @param exporter.startupProbe.failureThreshold Failure threshold for startupProbe
  ## @param exporter.startupProbe.successThreshold Success threshold for startupProbe
  ##
  startupProbe:
    enabled: false
    initialDelaySeconds: 5
    periodSeconds: 10
    timeoutSeconds: 1
    failureThreshold: 15
    successThreshold: 1
  ## @param exporter.customLivenessProbe Custom livenessProbe that overrides the default one
  ##
  customLivenessProbe: {}
  ## @param exporter.customReadinessProbe Custom readinessProbe that overrides the default one
  ##
  customReadinessProbe: {}
  ## @param exporter.customStartupProbe Custom startupProbe that overrides the default one
  ##
  customStartupProbe: {}
  ## Harbor Exporter resource requests and limits
  ## ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
  ## @param exporter.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, micro, small, medium, large, xlarge, 2xlarge). This is ignored if exporter.resources is set (exporter.resources is recommended for production).
  ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
  ##
  resourcesPreset: "nano"
  ## @param exporter.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
  ## Example:
  ## resources:
  ##   requests:
  ##     cpu: 2
  ##     memory: 512Mi
  ##   limits:
  ##     cpu: 3
  ##     memory: 1024Mi
  ##
  resources: {}
  ## Configure Exporter pods Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod
  ## @param exporter.podSecurityContext.enabled Enabled Exporter pods' Security Context
  ## @param exporter.podSecurityContext.fsGroupChangePolicy Set filesystem group change policy
  ## @param exporter.podSecurityContext.sysctls Set kernel settings using the sysctl interface
  ## @param exporter.podSecurityContext.supplementalGroups Set filesystem extra groups
  ## @param exporter.podSecurityContext.fsGroup Set Exporter pod's Security Context fsGroup
  ##
  podSecurityContext:
    enabled: true
    fsGroupChangePolicy: Always
    sysctls: []
    supplementalGroups: []
    fsGroup: 1001
  ## Configure Exporter containers (only main one) Security Context
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container
  ## @param exporter.containerSecurityContext.enabled Enabled containers' Security Context
  ## @param exporter.containerSecurityContext.seLinuxOptions [object,nullable] Set SELinux options in container
  ## @param exporter.containerSecurityContext.runAsUser Set containers' Security Context runAsUser
  ## @param exporter.containerSecurityContext.runAsGroup Set containers' Security Context runAsGroup
  ## @param exporter.containerSecurityContext.runAsNonRoot Set container's Security Context runAsNonRoot
  ## @param exporter.containerSecurityContext.privileged Set container's Security Context privileged
  ## @param exporter.containerSecurityContext.readOnlyRootFilesystem Set container's Security Context readOnlyRootFilesystem
  ## @param exporter.containerSecurityContext.allowPrivilegeEscalation Set container's Security Context allowPrivilegeEscalation
  ## @param exporter.containerSecurityContext.capabilities.drop List of capabilities to be dropped
  ## @param exporter.containerSecurityContext.seccompProfile.type Set container's Security Context seccomp profile
  ##
  containerSecurityContext:
    enabled: true
    seLinuxOptions: {}
    runAsUser: 1001
    runAsGroup: 1001
    runAsNonRoot: true
    privileged: false
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    capabilities:
      drop: ["ALL"]
    seccompProfile:
      type: "RuntimeDefault"
  ## @param exporter.updateStrategy.type The update strategy for deployments with persistent volumes: RollingUpdate or Recreate. Set it as Recreate when RWM for volumes isn't supported
  ## If replicas = 1, an update can get "stuck", as the previous pod remains attached to the
  ## PV, and the "incoming" pod can never start. Changing the strategy to "Recreate" will
  ## terminate the single previous pod, so that the new, incoming pod can attach to the PV
  ##
  updateStrategy:
    type: RollingUpdate
  ## @param exporter.lifecycleHooks LifecycleHook to set additional configuration at startup, e.g. LDAP settings via REST API. Evaluated as a template
  ##
  lifecycleHooks: {}
  ## @param exporter.hostAliases Exporter pods host aliases
  ##
  hostAliases: []
  ## @param exporter.podLabels Add additional labels to the pod (evaluated as a template)
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
  ##
  podLabels: {}
  ## @param exporter.podAnnotations Annotations to add to the exporter pod
  ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
  ##
  podAnnotations: {}
  ## @param exporter.podAffinityPreset Harbor Exporter Pod affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
  ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAffinityPreset: ""
  ## @param exporter.podAntiAffinityPreset Harbor Exporter Pod anti-affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`
  ## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity
  ##
  podAntiAffinityPreset: soft
  ## Node affinity preset
  ## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  ##
  nodeAffinityPreset:
    ## @param exporter.nodeAffinityPreset.type Harbor Exporter Node affinity preset type. Ignored if `exporter.affinity` is set. Allowed values: `soft` or `hard`
    ##
    type: ""
    ## @param exporter.nodeAffinityPreset.key Harbor Exporter Node label key to match Ignored if `exporter.affinity` is set.
    ## E.g.
    ## key: "kubernetes.io/e2e-az-name"
    ##
    key: ""
    ## @param exporter.nodeAffinityPreset.values Harbor Exporter Node label values to match. Ignored if `exporter.affinity` is set.
    ## E.g.
    ## values:
    ##   - e2e-az1
    ##   - e2e-az2
    ##
    values: []
  ## @param exporter.affinity Harbor Exporter Affinity for pod assignment
  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  ## Note: `exporter.podAffinityPreset`, `exporter.podAntiAffinityPreset`, and `exporter.nodeAffinityPreset` will be ignored when it's set
  ##
  affinity: {}
  ## @param exporter.priorityClassName Exporter pods Priority Class Name
  ## ref: https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/#priorityclass
  ##
  priorityClassName: ""
  ## @param exporter.schedulerName Name of the k8s scheduler (other than default)
  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
  ##
  schedulerName: ""
  ## @param exporter.nodeSelector Harbor Exporter Node labels for pod assignment
  ## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/
  ##
  nodeSelector: {}
  ## @param exporter.tolerations Harbor Exporter Tolerations for pod assignment
  ## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  ##
  tolerations: []
  ## @param exporter.topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains. Evaluated as a template
  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods
  ##
  topologySpreadConstraints: []
  ## @param exporter.initContainers Add additional init containers to the pod (evaluated as a template)
  ##
  initContainers: []
  ## Pod Disruption Budget configuration
  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb
  ## @param exporter.pdb.create Enable/disable a Pod Disruption Budget creation
  ## @param exporter.pdb.minAvailable Minimum number/percentage of pods that should remain scheduled
  ## @param exporter.pdb.maxUnavailable Maximum number/percentage of pods that may be made unavailable. Defaults to `1` if both `exporter.pdb.minAvailable` and `exporter.pdb.maxUnavailable` are empty.
  ##
  pdb:
    create: true
    minAvailable: ""
    maxUnavailable: ""
  ## @param exporter.extraVolumeMounts
  ##
  extraVolumeMounts: []
  ## @param exporter.extraVolumes
  ##
  extraVolumes: []
  ## @param exporter.sidecars Attach additional containers to the pod (evaluated as a template)
  ##
  sidecars: []
  ## @param exporter.automountServiceAccountToken Mount Service Account token in pod
  ##
  automountServiceAccountToken: false
  ## Harbor Exporter ServiceAccount configuration
  ##
  serviceAccount:
    ## @param exporter.serviceAccount.create Specifies whether a ServiceAccount should be created
    ##
    create: false
    ## @param exporter.serviceAccount.name The name of the ServiceAccount to use.
    ## If not set and create is true, a name is generated using the common.names.fullname template
    ##
    name: ""
    ## @param exporter.serviceAccount.automountServiceAccountToken Allows auto mount of ServiceAccountToken on the serviceAccount created
    ##
    automountServiceAccountToken: false
    ## @param exporter.serviceAccount.annotations Additional custom annotations for the ServiceAccount
    ##
    annotations: {}
  ## Exporter service configuration
  ##
  service:
    ## @param exporter.service.ports.metrics Exporter HTTP service port
    ##
    ports:
      metrics: 8001
  ## Network Policies
  ## Ref: https://kubernetes.io/docs/concepts/services-networking/network-policies/
  ##
  networkPolicy:
    ## @param exporter.networkPolicy.enabled Specifies whether a NetworkPolicy should be created
    ##
    enabled: true
    ## @param exporter.networkPolicy.allowExternal Don't require server label for connections
    ## The Policy model to apply. When set to false, only pods with the correct
    ## server label will have network access to the ports server is listening
    ## on. When true, server will accept connections from any source
    ## (with the correct destination port).
    ##
    allowExternal: true
    ## @param exporter.networkPolicy.allowExternalEgress Allow the pod to access any range of port and all destinations.
    ##
    allowExternalEgress: true
    ## @param exporter.networkPolicy.extraIngress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraIngress:
    ##   - ports:
    ##       - port: 1234
    ##     from:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    extraIngress: []
    ## @param exporter.networkPolicy.extraEgress [array] Add extra ingress rules to the NetworkPolicy
    ## e.g:
    ## extraEgress:
    ##   - ports:
    ##       - port: 1234
    ##     to:
    ##       - podSelector:
    ##           - matchLabels:
    ##               - role: frontend
    ##       - podSelector:
    ##           - matchExpressions:
    ##               - key: role
    ##                 operator: In
    ##                 values:
    ##                   - frontend
    ##
    extraEgress: []
    ## @param exporter.networkPolicy.ingressNSMatchLabels [object] Labels to match to allow traffic from other namespaces
    ## @param exporter.networkPolicy.ingressNSPodMatchLabels [object] Pod labels to match to allow traffic from other namespaces
    ##
    ingressNSMatchLabels: {}
    ingressNSPodMatchLabels: {}
## @section PostgreSQL Parameters
##

## PostgreSQL chart configuration
## ref: https://github.com/bitnami/charts/blob/main/bitnami/postgresql/values.yaml
## @param postgresql.enabled Switch to enable or disable the PostgreSQL helm chart
## @param postgresql.auth.enablePostgresUser Assign a password to the "postgres" admin user. Otherwise, remote access will be blocked for this user
## @param postgresql.auth.postgresPassword Password for the "postgres" admin user
## @param postgresql.auth.existingSecret Name of existing secret to use for PostgreSQL credentials
## @param postgresql.architecture PostgreSQL architecture (`standalone` or `replication`)
## @param postgresql.primary.extendedConfiguration Extended PostgreSQL Primary configuration (appended to main or default configuration)
## @param postgresql.primary.initdb.scripts [object] Initdb scripts to create Harbor databases
##
postgresql:
  enabled: true
  ## Override PostgreSQL default image as 14.x is not supported https://goharbor.io/docs/2.4.0/install-config/
  ## ref: https://github.com/bitnami/containers/tree/main/bitnami/postgresql
  ## @param postgresql.image.registry [default: REGISTRY_NAME] PostgreSQL image registry
  ## @param postgresql.image.repository [default: REPOSITORY_NAME/postgresql] PostgreSQL image repository
  ## @skip postgresql.image.tag PostgreSQL image tag (immutable tags are recommended)
  ## @param postgresql.image.digest PostgreSQL image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag
  ##
  image:
    registry: docker.io
    repository: bitnami/postgresql
    tag: 13.15.0-debian-12-r19
    digest: ""
  auth:
    enablePostgresUser: true
    postgresPassword: not-secure-database-password
    existingSecret: ""
  architecture: standalone
  primary:
    extendedConfiguration: |
      max_connections = 1024
    initdb:
      scripts:
        initial-registry.sql: |
          CREATE DATABASE registry ENCODING 'UTF8';
          \c registry;
          CREATE TABLE schema_migrations(version bigint not null primary key, dirty boolean not null);
    ## PostgreSQL Primary resource requests and limits
    ## ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
    ## @param postgresql.primary.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, small, medium, large, xlarge, 2xlarge). This is ignored if primary.resources is set (primary.resources is recommended for production).
    ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
    ##
    resourcesPreset: "nano"
    ## @param postgresql.primary.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
    ## Example:
    ## resources:
    ##   requests:
    ##     cpu: 2
    ##     memory: 512Mi
    ##   limits:
    ##     cpu: 3
    ##     memory: 1024Mi
    ##
    resources: {}
## External PostgreSQL configuration
## All of these values are only used when postgresql.enabled is set to false
## @param externalDatabase.host Database host
## @param externalDatabase.port Database port number
## @param externalDatabase.user Non-root username for Harbor
## @param externalDatabase.password Password for the non-root username for Harbor
## @param externalDatabase.sslmode External database ssl mode
## @param externalDatabase.coreDatabase External database name for core
##
externalDatabase:
  host: localhost
  port: 5432
  user: bn_harbor
  password: ""
  sslmode: disable
  coreDatabase: ""
## @section Redis&reg; parameters
##

## Redis&reg; chart configuration
## ref: https://github.com/bitnami/charts/blob/main/bitnami/redis/values.yaml
## @param redis.enabled Switch to enable or disable the Redis&reg; helm
## @param redis.auth.enabled Enable password authentication
## @param redis.auth.password Redis&reg; password
## @param redis.auth.existingSecret The name of an existing secret with Redis&reg; credentials
## @param redis.architecture Redis&reg; architecture. Allowed values: `standalone` or `replication`
## @param redis.sentinel.enabled Use Redis&reg; Sentinel on Redis&reg; pods.
## @param redis.sentinel.masterSet Master set name
## @param redis.sentinel.service.ports.sentinel Redis&reg; service port for Redis&reg; Sentinel
##
redis:
  enabled: true
  auth:
    enabled: false
    ## Redis&reg; password (both master and slave). Defaults to a random 10-character alphanumeric string if not set and auth.enabled is true.
    ## It should always be set using the password value or in the existingSecret to avoid issues
    ## with Harbor.
    ## The password value is ignored if existingSecret is set
    ##
    password: ""
    existingSecret: ""
  architecture: standalone
  sentinel:
    enabled: false
    masterSet: mymaster
    service:
      ports:
        sentinel: 26379
  master:
    ## Redis&reg; master resource requests and limits
    ## ref: https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/
    ## @param redis.master.resourcesPreset Set container resources according to one common preset (allowed values: none, nano, small, medium, large, xlarge, 2xlarge). This is ignored if master.resources is set (master.resources is recommended for production).
    ## More information: https://github.com/bitnami/charts/blob/main/bitnami/common/templates/_resources.tpl#L15
    ##
    resourcesPreset: "nano"
    ## @param redis.master.resources Set container requests and limits for different resources like CPU or memory (essential for production workloads)
    ## Example:
    ## resources:
    ##   requests:
    ##     cpu: 2
    ##     memory: 512Mi
    ##   limits:
    ##     cpu: 3
    ##     memory: 1024Mi
    ##
    resources: {}
## External Redis&reg; configuration
## All of these values are only used when redis.enabled is set to false
## @param externalRedis.host Redis&reg; host
## @param externalRedis.port Redis&reg; port number
## @param externalRedis.password Redis&reg; password
## @param externalRedis.coreDatabaseIndex Index for core database
## @param externalRedis.jobserviceDatabaseIndex Index for jobservice database
## @param externalRedis.registryDatabaseIndex Index for registry database
## @param externalRedis.trivyAdapterDatabaseIndex Index for trivy adapter database
##
externalRedis:
  host: localhost
  port: 6379
  password: ""
  coreDatabaseIndex: "0"
  jobserviceDatabaseIndex: "1"
  registryDatabaseIndex: "2"
  trivyAdapterDatabaseIndex: "5"
  ## Redis&reg; sentinel configuration
  ## @param externalRedis.sentinel.enabled If external redis with sentinal is used, set it to `true`
  ## @param externalRedis.sentinel.masterSet Name of sentinel masterSet if sentinel is used
  ## @param externalRedis.sentinel.hosts Sentinel hosts and ports in the format
  ##
  sentinel:
    enabled: false
    masterSet: "mymaster"
    hosts: ""
## @section Harbor metrics parameters
##
metrics:
  ## @param metrics.enabled Whether or not to enable metrics for different
  ##
  enabled: false
  ## @param metrics.path Path where metrics are exposed
  ##
  path: /metrics
  ## Prometheus Operator ServiceMonitor configuration
  ##
  serviceMonitor:
    ## @param metrics.serviceMonitor.enabled if `true`, creates a Prometheus Operator ServiceMonitor (requires `metrics.enabled` to be `true`)
    ##
    enabled: false
    ## @param metrics.serviceMonitor.namespace Namespace in which Prometheus is running
    ##
    namespace: ""
    ## @param metrics.serviceMonitor.interval Interval at which metrics should be scraped
    ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
    ##
    interval: ""
    ## @param metrics.serviceMonitor.scrapeTimeout Timeout after which the scrape is ended
    ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
    ##
    scrapeTimeout: ""
    ## @param metrics.serviceMonitor.labels Additional labels that can be used so ServiceMonitor will be discovered by Prometheus
    ##
    labels: {}
    ## @param metrics.serviceMonitor.selector Prometheus instance selector labels
    ## ref: https://github.com/bitnami/charts/tree/main/bitnami/prometheus-operator#prometheus-configuration
    ##
    selector: {}
    ## @param metrics.serviceMonitor.relabelings RelabelConfigs to apply to samples before scraping
    ##
    relabelings: []
    ## @param metrics.serviceMonitor.metricRelabelings MetricRelabelConfigs to apply to samples before ingestion
    ##
    metricRelabelings: []
    ## @param metrics.serviceMonitor.honorLabels Specify honorLabels parameter to add the scrape endpoint
    ##
    honorLabels: false
    ## @param metrics.serviceMonitor.jobLabel The name of the label on the target service to use as the job name in prometheus.
    ##
    jobLabel: ""
